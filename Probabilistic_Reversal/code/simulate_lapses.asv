clear all

%% Simulate individual participants
num_subjects = 20;
Alldata = cell(num_subjects,1);
sim_params = zeros(num_subjects, 3);

for i=1:num_subjects
    % alpha, stick, eps
    while true
        alpha = normrnd(0.3,0.1);
        eps = normrnd(0.05, 0.02);
        n_trials_lapse = floor(normrnd(300,100));
        if alpha > 0 && alpha < 1 && eps > 0 && eps < 1 && ...
                n_trials_lapse > 0 && n_trials_lapse < 500
            break
        end
    end
    stick = normrnd(0, 0.05);
    start_trial_lapse = ceil(rand * 300);

    starts(i) = start_trial_lapse;
    durations(i) = n_trials_lapse;

    sim_params(i,:) = [alpha, stick, eps];
    
    % simulate data for this subject
    Alldata{i} = static_model([alpha,stick,eps], start_trial_lapse, n_trials_lapse);
end

%% fit models
Ms = [];

curr_model = [];
curr_model.name = 'static_model';
curr_model.pMin = [1e-6 -1 1e-6];
curr_model.pMax = [1 1 1];
curr_model.pnames = {'alpha','stick','epsilon'};

Ms{1}=curr_model;

curr_model = [];
curr_model.name = 'dynamic_model';
curr_model.pMin = [1e-6 -1 1e-6 1e-6];
curr_model.pMax = [1 1 1 1];
curr_model.pnames = {'alpha','stick','lapse','recover'};

Ms{2}=curr_model;

%% 
All_Params = cell(length(Ms),1);
All_fits = cell(length(Ms),1);

for m=1:length(Ms)
    fit_model = Ms{m};
    pmin = fit_model.pMin;
    pmax = fit_model.pMax;

    fitmeasures = cell(num_subjects,1);
    fitparams = cell(num_subjects,1);
    
    parfor s = 1:num_subjects
        data = Alldata{s};
        par  = pmin+rand().*(pmax-pmin);

        myfitfun = @(p) feval([fit_model.name,'_llh'],p,data);
        rng default % For reproducibility
        opts = optimoptions(@fmincon,'Algorithm','sqp');
        problem = createOptimProblem('fmincon','objective',...
            myfitfun,'x0',par,'lb',pmin,'ub',pmax,'options',opts);
        gs = GlobalSearch;
        [param,llh] = run(gs,problem);

        ntrials = size(data,1);

        % add one for capacity
        AIC = 2*llh + 2*length(param);
        BIC = 2*llh + log(ntrials)*length(param);
        AIC0 = -2*log(1/3)*ntrials;
        psr2 = (AIC0-AIC)/AIC0;

        fitmeasures{s} = [s llh AIC BIC psr2 AIC0];
        fitparams{s} = param;
    end

All_Params{m} = cell2mat(fitparams);
All_fits{m} = cell2mat(fitmeasures);
end

temp = All_fits;
All_fits = zeros(num_subjects,size(temp{1},2),length(Ms));
for i=1:length(Ms)
    All_fits(:,:,i) = temp{i};
end
    
%% plot individual validation
n_subj_to_plot = 6;
niters = 50;
AIC_diff = AICs(:,dynamic_model_ind) - AICs(:,static_model_ind);
[~, idx] = sort(AIC_diff);
subjects = 1:num_subjects;
subjects_ranked = subjects(idx);
figure('Position',[200 200 1600 600])
colororder(gca().ColorOrder(4:end,:));
for subj_ind=1:n_subj_to_plot
    subplot(2,floor(n_subj_to_plot/2),subj_ind)
    this_ID = subjects_ranked(subj_ind); 

    % plot switches
    for s=1:9
        xline(s*50,'--');
        hold on
    end

    this_data_all = zeros(500,6);
    this_static_sim = zeros(500,6);
    this_dynamic_sim = zeros(500,6);
    for it=1:niters
        this_data = static_model(sim_params(this_ID,:), starts(this_ID), durations(this_ID));
        this_data_all = this_data_all + this_data;
        this_static_sim = this_static_sim + static_model(All_Params{static_model_ind}(this_ID,:));
        latent_st_traj = dynamic_model_latent(All_Params{dynamic_model_ind}(this_ID,:), this_data);
        this_dynamic_sim = this_dynamic_sim + dynamic_model(All_Params{dynamic_model_ind}(this_ID,:), latent_st_traj);
    end
    this_data_all = this_data_all / niters;
    this_static_sim = this_static_sim / niters;
    this_dynamic_sim = this_dynamic_sim / niters;

    area([starts(this_ID) min(500,starts(this_ID)+durations(this_ID))],[1 1],...
        'basevalue',0,'EdgeColor','none','FaceColor','black','FaceAlpha',0.05);
    hold on

    window = 50;
    smoothing_window = 10;
    % Apply moving mean to each block of 50 data points
    for i = 0:9
        start = i*window + 1;
        stop = start + window - 1;
        plot(start:stop, movmean(this_data_all(start:stop,4),smoothing_window),'k','LineWidth',2)
        hold on
        plot(start:stop, movmean(this_static_sim(start:stop,4),smoothing_window),'r','LineWidth',2)
        hold on
        plot(start:stop, movmean(this_dynamic_sim(start:stop,4),smoothing_window),'g','LineWidth',2)
    end

    title(['Î”AIC=', sprintf('%.1f',AIC_diff(subjects==this_ID))]);
    hold on

    if subj_ind == 1
        legend({'','','','','','','','','switch','lapse','data', 'static', 'dynamic'}, 'Interpreter','none')
    end
end

saveas(gcf, '../plots/individual_learning_curves.png')
saveas(gcf, '../plots/individual_learning_curves.svg')


%% Simulate large number of participants
clear all

num_subjects = 3000;
Alldata = cell(num_subjects,1);
sim_params = zeros(num_subjects, 3);

alpha_sample = @(x) unifrnd(0, 0.6);
stick_sample = @(x) unifrnd(-0.3, 0.3);
eps_sample = @(x) unifrnd(0, 0.2);

for i=1:num_subjects
    % alpha, stick, eps
    while true
        alpha = alpha_sample(0);
        eps = eps_sample(0);
        n_trials_lapse = unifrnd(0,500);
        if alpha > 0 && alpha < 1 && eps > 0 && eps < 1 && ...
                n_trials_lapse > 0 && n_trials_lapse < 500
            break
        end
    end
    stick = stick_sample(0);
    start_trial_lapse = ceil(rand * 100);

    starts(i) = start_trial_lapse;
    durations(i) = min(n_trials_lapse,500-start_trial_lapse);

    sim_params(i,:) = [alpha, stick, eps];
    
    % simulate data for this subject
    Alldata{i} = static_model([alpha,stick,eps], start_trial_lapse, n_trials_lapse);
end

%% fit models
Ms = [];

curr_model = [];
curr_model.name = 'static_model';
curr_model.pMin = [1e-6 -1 1e-6];
curr_model.pMax = [1 1 1];
curr_model.pnames = {'alpha','stick','epsilon'};

Ms{1}=curr_model;

curr_model = [];
curr_model.name = 'dynamic_model';
curr_model.pMin = [1e-6 -1 1e-6 1e-6];
curr_model.pMax = [1 1 1 1];
curr_model.pnames = {'alpha','stick','lapse','recover'};

Ms{2}=curr_model;

All_Params = cell(length(Ms),1);
All_fits = cell(length(Ms),1);

for m=1:length(Ms)
    fit_model = Ms{m};
    pmin = fit_model.pMin;
    pmax = fit_model.pMax;

    fitmeasures = cell(num_subjects,1);
    fitparams = cell(num_subjects,1);
    
    parfor s = 1:num_subjects
        data = Alldata{s};
        par  = pmin+rand().*(pmax-pmin);

        % Set starting values of dynamic model parameters to the best fit
        % static model parameters
        if contains(fit_model.name, 'dynamic')
            dynamic_model = fit_model;
            static_model_ind = find(contains(cellfun(@(x) x.name, Ms, 'UniformOutput', false), 'static'));
            static_model = Ms{static_model_ind};
            for z = 1:length(dynamic_model.pnames)
                this_p = dynamic_model.pnames{z};
                if sum(strcmp(this_p, static_model.pnames)) > 0
                    par(strcmp(this_p, dynamic_model.pnames)) = All_Params{static_model_ind}(s, strcmp(this_p, Ms{static_model_ind}.pnames));
                end
            end
            par(strcmp('lapse', dynamic_model.pnames)) = All_Params{static_model_ind}(s, strcmp('epsilon', static_model.pnames));
            par(strcmp('recover', dynamic_model.pnames)) = 1 - All_Params{static_model_ind}(s, strcmp('epsilon', static_model.pnames));
        end

        myfitfun = @(p) feval([fit_model.name,'_llh'],p,data);
        rng default % For reproducibility
        opts = optimoptions(@fmincon,'Algorithm','sqp');
        problem = createOptimProblem('fmincon','objective',...
            myfitfun,'x0',par,'lb',pmin,'ub',pmax,'options',opts);
        gs = GlobalSearch;
        [param,llh] = run(gs,problem);

        ntrials = size(data,1);

        % add one for capacity
        AIC = 2*llh + 2*length(param);
        BIC = 2*llh + log(ntrials)*length(param);
        AIC0 = -2*log(1/3)*ntrials;
        psr2 = (AIC0-AIC)/AIC0;

        fitmeasures{s} = [s llh AIC BIC psr2 AIC0];
        fitparams{s} = param;
    end

All_Params{m} = cell2mat(fitparams);
All_fits{m} = cell2mat(fitmeasures);
end
toc

temp = All_fits;
All_fits = zeros(num_subjects,size(temp{1},2),length(Ms));
for i=to_fit
    All_fits(:,:,i) = temp{i};
end

%% plot validation
att_model_ind = 2;
no_att_model_ind = 1;

niters = 50;

MSE = zeros(num_subjects,2);

parfor this_ID=1:num_subjects
    this_data_all = zeros(500,6);
    this_static_sim = zeros(500,6);
    this_dynamic_sim = zeros(500,6);
    for it=1:niters
        this_data = RL(sim_params(this_ID,:), starts(this_ID), durations(this_ID));
        this_data_all = this_data_all + this_data;
        this_static_sim = this_static_sim + RL(All_Params{1}(this_ID,:));
        att_traj = RL_lapse_latent(All_Params{2}(this_ID,:), this_data);
        this_dynamic_sim = this_dynamic_sim + RL_lapse(All_Params{2}(this_ID,:), att_traj);
    end
    this_data_all = this_data_all / niters;
    this_static_sim = this_static_sim / niters;
    this_dynamic_sim = this_dynamic_sim / niters;

    window = 20;
    this_data_all = movmean(this_data_all(:,4),window);
    this_static_sim = movmean(this_static_sim(:,4),window);
    this_dynamic_sim = movmean(this_dynamic_sim(:,4),window);

    MSE(this_ID,:) = [sum((this_data_all - this_static_sim).^2) / length(this_data_all), ...
        sum((this_data_all - this_dynamic_sim).^2) / length(this_data_all)];
end

%% plot MSE against length of lapse
plot(durations, MSE(:,1), '.', 'MarkerFaceColor', 'r', 'MarkerEdgeColor','r')
hold on
p = polyfit(durations,MSE(:,1),2);
x1 = linspace(0,500);
y1 = polyval(p,x1);
plot(x1,y1,'k','LineWidth',2)
hold on
plot(durations, MSE(:,2), '.', 'MarkerFaceColor', 'g', 'MarkerEdgeColor','g')
hold on
p = polyfit(durations,MSE(:,2),2);
y1 = polyval(p,x1);
plot(x1,y1,'k','LineWidth',2)
ylim([0,0.05])

xlabel('Duration of lapse (Trials)')
ylabel('MSE per trial')

legend({'RL','','RL_lapse',''},'Interpreter','none')
title('Difference in learning curves with sim data')

saveas(gcf,'plots/fig2B_MSE.svg')
saveas(gcf,'plots/fig2B_MSE.png')

%% plot AIC against length of lapse
plot(durations, All_fits(:,3,1), '.', 'MarkerFaceColor', 'r', 'MarkerEdgeColor','r')
hold on
p = polyfit(durations,All_fits(:,3,1),2);
x1 = linspace(0,500);
y1 = polyval(p,x1);
plot(x1,y1,'k','LineWidth',2)
hold on
plot(durations, All_fits(:,3,2), '.', 'MarkerFaceColor', 'g', 'MarkerEdgeColor','g')
hold on
p = polyfit(durations,All_fits(:,3,2),2);
y1 = polyval(p,x1);
plot(x1,y1,'k','LineWidth',2)

xlabel('Duration of lapse (Trials)')
ylabel('AIC')

legend({'RL','','RL_lapse',''},'Interpreter','none')
title('Difference in learning curves with sim data')

saveas(gcf,'plots/fig2B_AIC.svg')
saveas(gcf,'plots/fig2B_AIC.png')

%% plot difference in parameters against length of lapse
figure('Position',[300 300 1000 400])
for p=1:2
    subplot(1,2,p)
    plot(sim_params(:,p), All_Params{1}(:,p),'.','MarkerSize',20)
    hold on
    plot(sim_params(:,p), All_Params{2}(:,p),'.','MarkerSize',20)
    hold on
    plot(sim_params(:,p), sim_params(:,p), 'k', 'LineWidth',2);
    hold on
    legend({'RL', 'RL_lapse', ''}, 'Interpreter','none')
    title(Ms{1}.pnames{p})
    xlabel('True')
    ylabel('Inferred')
end

%% plot |inferred - true| over inferred binned
figure('Position',[300 300 1000 400])
for p=1:2
    subplot(1,2,p)

    x = [All_Params{1}(:,p), All_Params{2}(:,p)];
    y = [All_Params{1}(:,p), All_Params{2}(:,p)];
    y = abs(y - sim_params(:,p)); 

    % Define the number of bins for each column of y
    numBins = 4;
    
    % Initialize a matrix to store the bin counts and bin means for each column of y
    binCounts = zeros(numBins, size(y, 2));
    binMeans = zeros(numBins, size(y, 2));
    
    % Loop over each column of y
    for i = 1:size(y, 2)
        % Compute the bin edges based on the corresponding values in x
        binEdges = linspace(min(x(:,i)), max(x(:,i)), numBins+1);
        
        % Compute the bin counts and means for this column of y
        [binCounts(:, i), ~, binIdx] = histcounts(x(:,i), binEdges);
        binMeans(:, i) = accumarray(binIdx, y(:, i), [], @mean);
    end
    
    % Compute the standard error of the mean for each bin
    sem = std(y) ./ sqrt(binCounts);
    
    % Define the custom colors for the bars
    colors = [0.8588 0.5176 0.5765; 0.5098 0.6784 0.7922];
    
    % Define the offset for the error bars
    offset = (binEdges(2) - binEdges(1)) / 2;

    % Create the bar plot
    barPlot = bar(binMeans, 'grouped');
    
    % Set the custom colors for the bars
    for i = 1:size(y, 2)
        set(gca, 'ColorOrderIndex', i);
        set(barPlot(i), 'FaceColor', colors(i,:));
    end
    
    % Add error bars
    hold on;
    for i = 1:size(y, 2)
        this_x = 1:numBins;
        this_x = this_x + (i-1.5)*0.28;
        errorbar(this_x, binMeans(:, i), sem(:, i), '.', 'Color', 'k', 'LineWidth', 1.5);
    end
    hold off;
    
    % Label the x-axis with the bin edges
    xticklabels(sprintfc('%0.2f to %0.2f', ...
        [binEdges(1:end-1); binEdges(2:end)]'));

    xlabel('Inferred')
    ylabel('|Inferred - True|')

    title(Ms{1}.pnames{p})
    
    % Add a legend for the two columns of y
    legend({'RL', 'RL_lapse'}, 'Interpreter','none', 'Location','northwest');
end

%% plot |inferred - true| over true binned
figure('Position',[300 300 1000 400])
for p=1:2
    subplot(1,2,p)

    x = sim_params(:,p);
    y = [All_Params{1}(:,p), All_Params{2}(:,p)];
    y = abs(y - sim_params(:,p)); 

    % Define the number of bins for each column of y
    numBins = 3;
    
    % Initialize a matrix to store the bin counts and bin means for each column of y
    binCounts = zeros(numBins, size(y, 2));
    binMeans = zeros(numBins, size(y, 2));
    
    % Loop over each column of y
    for i = 1:size(y, 2)
        % Compute the bin edges based on the corresponding values in x
        binEdges = linspace(min(x), max(x), numBins+1);
        
        % Compute the bin counts and means for this column of y
        [binCounts(:, i), ~, binIdx] = histcounts(x, binEdges);
        binMeans(:, i) = accumarray(binIdx, y(:, i), [], @mean);
    end
    
    % Compute the standard error of the mean for each bin
    sem = std(y) ./ sqrt(binCounts);
    
    % Define the custom colors for the bars
    colors = [0.8588 0.5176 0.5765; 0.5098 0.6784 0.7922];
    
    % Define the offset for the error bars
    offset = (binEdges(2) - binEdges(1)) / 2;

    % Create the bar plot
    barPlot = bar(binMeans, 'grouped');
    
    % Set the custom colors for the bars
    for i = 1:size(y, 2)
        set(gca, 'ColorOrderIndex', i);
        set(barPlot(i), 'FaceColor', colors(i,:));
    end
    
    % Add error bars
    hold on;
    for i = 1:size(y, 2)
        this_x = 1:numBins;
        this_x = this_x + (i-1.5)*0.28;
        errorbar(this_x, binMeans(:, i), sem(:, i), '.', 'Color', 'k', 'LineWidth', 1.5);
    end
    hold off;
    
    % Label the x-axis with the bin edges
    xticklabels(sprintfc('%0.2f to %0.2f', ...
        [binEdges(1:end-1); binEdges(2:end)]'));

    xlabel('True')
    ylabel('|Inferred - True|')

    title(Ms{1}.pnames{p})
    
    % Add a legend for the two columns of y
    legend({'RL', 'RL_lapse'}, 'Interpreter','none', 'Location','northwest');
end

saveas(gcf,'plots/fig2C1.svg')
saveas(gcf,'plots/fig2C1.png')

%% plot |inferred - true| over number of trials binned
figure('Position',[300 300 1000 400])
for p=1:2
    subplot(1,2,p)

    x = durations';
    y = [All_Params{1}(:,p), All_Params{2}(:,p)];
    y = abs(y - sim_params(:,p)); 

    % Compute the bin edges based on the corresponding values in x
    binEdges = [0 100 200 300 400 500];

    % Define the number of bins for each column of y
    numBins = length(binEdges) - 1;
    
    % Initialize a matrix to store the bin counts and bin means for each column of y
    binCounts = zeros(numBins, size(y, 2));
    binMeans = zeros(numBins, size(y, 2));
    
    % Loop over each column of y
    for i = 1:size(y, 2)
        % Compute the bin counts and means for this column of y
        [binCounts(:, i), ~, binIdx] = histcounts(x, binEdges);
        binMeans(:, i) = accumarray(binIdx, y(:, i), [], @mean);
    end
    
    % Compute the standard error of the mean for each bin
    sem = std(y) ./ sqrt(binCounts);
    
    % Define the custom colors for the bars
    colors = [0.8588 0.5176 0.5765; 0.5098 0.6784 0.7922];
    
    % Define the offset for the error bars
    offset = (binEdges(2) - binEdges(1)) / 2;

    % Create the bar plot
    barPlot = bar(binMeans, 'grouped');
    
    % Set the custom colors for the bars
    for i = 1:size(y, 2)
        set(gca, 'ColorOrderIndex', i);
        set(barPlot(i), 'FaceColor', colors(i,:));
    end
    
    % Add error bars
    hold on;
    for i = 1:size(y, 2)
        this_x = 1:numBins;
        this_x = this_x + (i-1.5)*0.28;
        errorbar(this_x, binMeans(:, i), sem(:, i), '.', 'Color', 'k', 'LineWidth', 1.5);
    end
    hold off;
    
    % Label the x-axis with the bin edges
    xticklabels(sprintfc('%d to %d', ...
        [binEdges(1:end-1); binEdges(2:end)]'));

    xlabel('Lapse duration (Trials)')
    ylabel('|Inferred - True|')

    title(Ms{1}.pnames{p})
    
    % Add a legend for the two columns of y
    legend({'RL', 'RL_lapse'}, 'Interpreter','none', 'Location','northwest');
end

saveas(gcf,'plots/fig2C2.svg')
saveas(gcf,'plots/fig2C2.png')